# Apache Kafka

–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–Ω–∞—è –ø–ª–∞—Ç—Ñ–æ—Ä–º–∞ –ø–æ—Ç–æ–∫–æ–≤–æ–π –ø–µ—Ä–µ–¥–∞—á–∏ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Å–æ–±—ã—Ç–∏–π –≤ —Ä–µ–∞–ª—å–Ω–æ–º –≤—Ä–µ–º–µ–Ω–∏.

---

## üéØ –ß—Ç–æ —Ç–∞–∫–æ–µ Kafka

**Apache Kafka** - —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–Ω–∞—è —Å–∏—Å—Ç–µ–º–∞ –æ–±–º–µ–Ω–∞ —Å–æ–æ–±—â–µ–Ω–∏—è–º–∏ (distributed streaming platform) –¥–ª—è –≤—ã—Å–æ–∫–æ–ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏ –ø–æ—Ç–æ–∫–æ–≤ —Å–æ–±—ã—Ç–∏–π.

### –û—Å–Ω–æ–≤–Ω—ã–µ –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏

1. **Messaging System** - –ø—É–±–ª–∏–∫–∞—Ü–∏—è –∏ –ø–æ–¥–ø–∏—Å–∫–∞ –Ω–∞ –ø–æ—Ç–æ–∫–∏ —Å–æ–æ–±—â–µ–Ω–∏–π
2. **Storage System** - –Ω–∞–¥–µ–∂–Ω–æ–µ —Ö—Ä–∞–Ω–µ–Ω–∏–µ –ø–æ—Ç–æ–∫–æ–≤ —Å–æ–±—ã—Ç–∏–π
3. **Stream Processing** - –æ–±—Ä–∞–±–æ—Ç–∫–∞ –ø–æ—Ç–æ–∫–æ–≤ –≤ —Ä–µ–∞–ª—å–Ω–æ–º –≤—Ä–µ–º–µ–Ω–∏

### –ö–ª—é—á–µ–≤—ã–µ —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∏

- **–í—ã—Å–æ–∫–∞—è –ø—Ä–æ–ø—É—Å–∫–Ω–∞—è —Å–ø–æ—Å–æ–±–Ω–æ—Å—Ç—å** - –º–∏–ª–ª–∏–æ–Ω—ã —Å–æ–æ–±—â–µ–Ω–∏–π –≤ —Å–µ–∫—É–Ω–¥—É
- **–ì–æ—Ä–∏–∑–æ–Ω—Ç–∞–ª—å–Ω–∞—è –º–∞—Å—à—Ç–∞–±–∏—Ä—É–µ–º–æ—Å—Ç—å** - –¥–æ–±–∞–≤–ª–µ–Ω–∏–µ –Ω–æ–≤—ã—Ö –±—Ä–æ–∫–µ—Ä–æ–≤
- **Fault-tolerance** - —Ä–µ–ø–ª–∏–∫–∞—Ü–∏—è –¥–∞–Ω–Ω—ã—Ö –º–µ–∂–¥—É –±—Ä–æ–∫–µ—Ä–∞–º–∏
- **–ù–∏–∑–∫–∞—è –∑–∞–¥–µ—Ä–∂–∫–∞** - –æ–±—Ä–∞–±–æ—Ç–∫–∞ –≤ –º–∏–ª–ª–∏—Å–µ–∫—É–Ω–¥–∞—Ö
- **–ü–æ—Å—Ç–æ—è–Ω–Ω–æ–µ —Ö—Ä–∞–Ω–µ–Ω–∏–µ** - —Å–æ–æ–±—â–µ–Ω–∏—è —Å–æ—Ö—Ä–∞–Ω—è—é—Ç—Å—è –Ω–∞ –¥–∏—Å–∫–µ
- **–ì–∞—Ä–∞–Ω—Ç–∏–∏ –¥–æ—Å—Ç–∞–≤–∫–∏** - at-least-once, at-most-once, exactly-once

---

## üìä –û—Å–Ω–æ–≤–Ω—ã–µ –∫–æ–Ω—Ü–µ–ø—Ü–∏–∏

### Topics (–¢–µ–º—ã)

**Topic** - –∫–∞—Ç–µ–≥–æ—Ä–∏—è –∏–ª–∏ –ø–æ—Ç–æ–∫, –≤ –∫–æ—Ç–æ—Ä—ã–π –ø—É–±–ª–∏–∫—É—é—Ç—Å—è —Å–æ–æ–±—â–µ–Ω–∏—è.

```
Topic: user_events

| Partition 0 | Partition 1 | Partition 2 |
|-------------|-------------|-------------|
| msg 0       | msg 1       | msg 2       |
| msg 3       | msg 4       | msg 5       |
| msg 6       | msg 7       | msg 8       |
```

**–•–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∏:**
- –ò–º—è —É–Ω–∏–∫–∞–ª—å–Ω–æ –≤ –∫–ª–∞—Å—Ç–µ—Ä–µ
- Multi-subscriber - –º–Ω–æ–≥–æ –ø–æ—Ç—Ä–µ–±–∏—Ç–µ–ª–µ–π
- Append-only log - –¥–æ–±–∞–≤–ª–µ–Ω–∏–µ –≤ –∫–æ–Ω–µ—Ü
- Retention policy - –≤—Ä–µ–º—è —Ö—Ä–∞–Ω–µ–Ω–∏—è —Å–æ–æ–±—â–µ–Ω–∏–π

### Partitions (–†–∞–∑–¥–µ–ª—ã)

**Partition** - —É–ø–æ—Ä—è–¥–æ—á–µ–Ω–Ω–∞—è, –Ω–µ–∏–∑–º–µ–Ω—è–µ–º–∞—è –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç—å —Å–æ–æ–±—â–µ–Ω–∏–π.

```
Topic: orders (3 partitions)

Partition 0:  [msg0] ‚Üí [msg3] ‚Üí [msg6] ‚Üí [msg9]
              offset: 0     1      2      3

Partition 1:  [msg1] ‚Üí [msg4] ‚Üí [msg7] ‚Üí [msg10]
              offset: 0     1      2      3

Partition 2:  [msg2] ‚Üí [msg5] ‚Üí [msg8] ‚Üí [msg11]
              offset: 0     1      2      3
```

**–ó–∞—á–µ–º partitions:**
- **–ü–∞—Ä–∞–ª–ª–µ–ª–∏–∑–º** - –∫–∞–∂–¥—ã–π partition –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç—Å—è –Ω–µ–∑–∞–≤–∏—Å–∏–º–æ
- **–ú–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏–µ** - —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø–æ —Ä–∞–∑–Ω—ã–º –±—Ä–æ–∫–µ—Ä–∞–º
- **Ordering** - –≥–∞—Ä–∞–Ω—Ç–∏—è –ø–æ—Ä—è–¥–∫–∞ –≤–Ω—É—Ç—Ä–∏ partition
- **Load balancing** - —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –Ω–∞–≥—Ä—É–∑–∫–∏

### Brokers (–ë—Ä–æ–∫–µ—Ä—ã)

**Broker** - —Å–µ—Ä–≤–µ—Ä Kafka, —Ö—Ä–∞–Ω—è—â–∏–π –∏ –æ–±—Å–ª—É–∂–∏–≤–∞—é—â–∏–π –¥–∞–Ω–Ω—ã–µ.

```
Kafka Cluster

‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  Broker 0   ‚îÇ  ‚îÇ  Broker 1   ‚îÇ  ‚îÇ  Broker 2   ‚îÇ
‚îÇ             ‚îÇ  ‚îÇ             ‚îÇ  ‚îÇ             ‚îÇ
‚îÇ Part 0 (L)  ‚îÇ  ‚îÇ Part 0 (F)  ‚îÇ  ‚îÇ Part 1 (L)  ‚îÇ
‚îÇ Part 1 (F)  ‚îÇ  ‚îÇ Part 2 (L)  ‚îÇ  ‚îÇ Part 0 (F)  ‚îÇ
‚îÇ Part 2 (F)  ‚îÇ  ‚îÇ Part 1 (F)  ‚îÇ  ‚îÇ Part 2 (F)  ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

L = Leader (—á–∏—Ç–∞–µ—Ç/–ø–∏—à–µ—Ç)
F = Follower (replica)
```

**–•–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∏:**
- –ö–∞–∂–¥—ã–π broker —Ö—Ä–∞–Ω–∏—Ç —á–∞—Å—Ç—å –¥–∞–Ω–Ω—ã—Ö
- Leader –¥–ª—è partition –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –≤—Å–µ —á—Ç–µ–Ω–∏—è/–∑–∞–ø–∏—Å–∏
- Followers —Ä–µ–ø–ª–∏—Ü–∏—Ä—É—é—Ç –¥–∞–Ω–Ω—ã–µ
- Zookeeper/KRaft –∫–æ–æ—Ä–¥–∏–Ω–∏—Ä—É–µ—Ç –±—Ä–æ–∫–µ—Ä—ã

### Producers (–ü—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª–∏)

**Producer** - –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ, –ø—É–±–ª–∏–∫—É—é—â–µ–µ —Å–æ–æ–±—â–µ–Ω–∏—è –≤ topics.

```php
// Producer –æ—Ç–ø—Ä–∞–≤–ª—è–µ—Ç —Å–æ–æ–±—â–µ–Ω–∏–µ
Producer ‚Üí Topic (orders) ‚Üí Partition (–ø–æ –∫–ª—é—á—É)
```

**–ö–ª—é—á–µ–≤—ã–µ –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏:**
- –í—ã–±–æ—Ä partition (–ø–æ –∫–ª—é—á—É, round-robin, custom)
- –ë–∞—Ç—á–∏–Ω–≥ —Å–æ–æ–±—â–µ–Ω–∏–π
- Compression (gzip, snappy, lz4, zstd)
- Acknowledgments (acks)

### Consumers (–ü–æ—Ç—Ä–µ–±–∏—Ç–µ–ª–∏)

**Consumer** - –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ, —á–∏—Ç–∞—é—â–µ–µ —Å–æ–æ–±—â–µ–Ω–∏—è –∏–∑ topics.

```
Consumer —á–∏—Ç–∞–µ—Ç —Å offset

Partition 0:  [msg0] ‚Üí [msg1] ‚Üí [msg2] ‚Üí [msg3]
                         ‚Üë
                      offset 1
                  (consumer —á–∏—Ç–∞–µ—Ç msg1)
```

**–•–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∏:**
- Pull model - consumer —Å–∞–º –∑–∞–±–∏—Ä–∞–µ—Ç —Å–æ–æ–±—â–µ–Ω–∏—è
- Offset tracking - –ø–æ–∑–∏—Ü–∏—è –≤ partition
- Consumer group –¥–ª—è –ø–∞—Ä–∞–ª–ª–µ–ª–∏–∑–º–∞

### Consumer Groups (–ì—Ä—É–ø–ø—ã –ø–æ—Ç—Ä–µ–±–∏—Ç–µ–ª–µ–π)

**Consumer Group** - –Ω–∞–±–æ—Ä consumers, —Å–æ–≤–º–µ—Å—Ç–Ω–æ –ø–æ—Ç—Ä–µ–±–ª—è—é—â–∏—Ö topic.

```
Topic: orders (3 partitions)

Consumer Group: order-processors

‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Consumer 1   ‚îÇ  ‚îÇ Consumer 2   ‚îÇ  ‚îÇ Consumer 3   ‚îÇ
‚îÇ Partition 0  ‚îÇ  ‚îÇ Partition 1  ‚îÇ  ‚îÇ Partition 2  ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

–ö–∞–∂–¥—ã–π partition –Ω–∞–∑–Ω–∞—á–µ–Ω –û–î–ù–û–ú–£ consumer –≤ –≥—Ä—É–ø–ø–µ
```

**–ü—Ä–∞–≤–∏–ª–∞:**
- –ö–∞–∂–¥—ã–π partition —á–∏—Ç–∞–µ—Ç—Å—è —Ç–æ–ª—å–∫–æ –æ–¥–Ω–∏–º consumer –≤ –≥—Ä—É–ø–ø–µ
- –ï—Å–ª–∏ consumers > partitions, –ª–∏—à–Ω–∏–µ –ø—Ä–æ—Å—Ç–∞–∏–≤–∞—é—Ç
- –ï—Å–ª–∏ consumers < partitions, –æ–¥–∏–Ω consumer —á–∏—Ç–∞–µ—Ç –Ω–µ—Å–∫–æ–ª—å–∫–æ partitions
- –†–∞–∑–Ω—ã–µ groups —á–∏—Ç–∞—é—Ç –≤—Å–µ —Å–æ–æ–±—â–µ–Ω–∏—è –Ω–µ–∑–∞–≤–∏—Å–∏–º–æ

### Offsets (–°–º–µ—â–µ–Ω–∏—è)

**Offset** - —É–Ω–∏–∫–∞–ª—å–Ω—ã–π –∏–¥–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ç–æ—Ä —Å–æ–æ–±—â–µ–Ω–∏—è –≤ partition.

```
Partition 0:
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ msg0 ‚îÇ msg1 ‚îÇ msg2 ‚îÇ msg3 ‚îÇ msg4 ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
offset: 0      1      2      3      4

Consumer commit offset: 3
‚Üí —Å–ª–µ–¥—É—é—â–µ–µ —á—Ç–µ–Ω–∏–µ —Å offset 3 (msg3)
```

**–£–ø—Ä–∞–≤–ª–µ–Ω–∏–µ offset:**
- **Auto-commit** - –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ —á–µ—Ä–µ–∑ –∏–Ω—Ç–µ—Ä–≤–∞–ª
- **Manual commit** - –≤—Ä—É—á–Ω—É—é –ø–æ—Å–ª–µ –æ–±—Ä–∞–±–æ—Ç–∫–∏
- **Stored in Kafka** - –≤ —Å–ø–µ—Ü–∏–∞–ª—å–Ω–æ–º topic `__consumer_offsets`

### Replication (–†–µ–ø–ª–∏–∫–∞—Ü–∏—è)

**Replication Factor** - –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∫–æ–ø–∏–π –∫–∞–∂–¥–æ–≥–æ partition.

```
Topic: payments, replication-factor: 3

Partition 0:
  Broker 0: Leader
  Broker 1: Follower (replica)
  Broker 2: Follower (replica)

Partition 1:
  Broker 1: Leader
  Broker 0: Follower
  Broker 2: Follower
```

**ISR (In-Sync Replicas):**
- Replicas, –∫–æ—Ç–æ—Ä—ã–µ —Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∏—Ä–æ–≤–∞–Ω—ã —Å leader
- Producer –º–æ–∂–µ—Ç —Ç—Ä–µ–±–æ–≤–∞—Ç—å acks –æ—Ç –≤—Å–µ—Ö ISR
- –ü—Ä–∏ –ø–∞–¥–µ–Ω–∏–∏ leader, –Ω–æ–≤—ã–π –≤—ã–±–∏—Ä–∞–µ—Ç—Å—è –∏–∑ ISR

---

## üÜö Kafka vs RabbitMQ

### –°—Ä–∞–≤–Ω–µ–Ω–∏–µ

| –ê—Å–ø–µ–∫—Ç | Kafka | RabbitMQ |
|--------|-------|----------|
| **–¢–∏–ø** | Distributed streaming platform | Message broker |
| **–ú–æ–¥–µ–ª—å** | Publish-Subscribe (log-based) | Flexible routing (queue/exchange) |
| **–•—Ä–∞–Ω–µ–Ω–∏–µ** | Persistent log (–¥–Ω–∏/–Ω–µ–¥–µ–ª–∏/forever) | –°–æ–æ–±—â–µ–Ω–∏–µ —É–¥–∞–ª—è–µ—Ç—Å—è –ø–æ—Å–ª–µ ack |
| **–ü—Ä–æ–ø—É—Å–∫–Ω–∞—è —Å–ø–æ—Å–æ–±–Ω–æ—Å—Ç—å** | –û—á–µ–Ω—å –≤—ã—Å–æ–∫–∞—è (millions/sec) | –°—Ä–µ–¥–Ω—è—è (thousands/sec) |
| **Latency** | –ù–∏–∑–∫–∞—è (ms) | –û—á–µ–Ω—å –Ω–∏–∑–∫–∞—è (microseconds) |
| **Ordering** | –ì–∞—Ä–∞–Ω—Ç–∏—Ä–æ–≤–∞–Ω –≤ partition | –ì–∞—Ä–∞–Ω—Ç–∏—Ä–æ–≤–∞–Ω –≤ queue |
| **Consumers** | Pull (consumer –∑–∞–±–∏—Ä–∞–µ—Ç) | Push (broker –æ—Ç–ø—Ä–∞–≤–ª—è–µ—Ç) |
| **Scalability** | –ì–æ—Ä–∏–∑–æ–Ω—Ç–∞–ª—å–Ω–∞—è (partitions) | –û–≥—Ä–∞–Ω–∏—á–µ–Ω–Ω–∞—è |
| **Use cases** | Event sourcing, stream processing, logs | Task queues, RPC, routing |
| **Complexity** | –í—ã—Å–æ–∫–∞—è | –°—Ä–µ–¥–Ω—è—è |

### –ö–æ–≥–¥–∞ Kafka

‚úÖ **Event sourcing** - —Ö—Ä–∞–Ω–µ–Ω–∏–µ –≤—Å–µ—Ö —Å–æ–±—ã—Ç–∏–π –¥–æ–º–µ–Ω–∞
‚úÖ **Stream processing** - –æ–±—Ä–∞–±–æ—Ç–∫–∞ –ø–æ—Ç–æ–∫–æ–≤ –≤ —Ä–µ–∞–ª—å–Ω–æ–º –≤—Ä–µ–º–µ–Ω–∏
‚úÖ **Log aggregation** - —Ü–µ–Ω—Ç—Ä–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—ã–µ –ª–æ–≥–∏ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–π
‚úÖ **Metrics collection** - —Å–±–æ—Ä –º–µ—Ç—Ä–∏–∫ —Å –º–Ω–æ–∂–µ—Å—Ç–≤–∞ –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤
‚úÖ **CDC (Change Data Capture)** - –æ—Ç—Å–ª–µ–∂–∏–≤–∞–Ω–∏–µ –∏–∑–º–µ–Ω–µ–Ω–∏–π –≤ –ë–î
‚úÖ **High throughput** - –º–∏–ª–ª–∏–æ–Ω—ã —Å–æ–æ–±—â–µ–Ω–∏–π –≤ —Å–µ–∫—É–Ω–¥—É
‚úÖ **Long retention** - –Ω—É–∂–Ω–æ —Ö—Ä–∞–Ω–∏—Ç—å —Å–æ–æ–±—â–µ–Ω–∏—è –¥–æ–ª–≥–æ
‚úÖ **Replay events** - –ø–µ—Ä–µ–æ–±—Ä–∞–±–æ—Ç–∫–∞ —Å–æ–±—ã—Ç–∏–π

### –ö–æ–≥–¥–∞ RabbitMQ

‚úÖ **Task queues** - —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –∑–∞–¥–∞—á –º–µ–∂–¥—É workers
‚úÖ **RPC (Request-Reply)** - —Å–∏–Ω—Ö—Ä–æ–Ω–Ω–∞—è –∫–æ–º–º—É–Ω–∏–∫–∞—Ü–∏—è
‚úÖ **Complex routing** - –º–∞—Ä—à—Ä—É—Ç–∏–∑–∞—Ü–∏—è –ø–æ –ø—Ä–∞–≤–∏–ª–∞–º
‚úÖ **Priority queues** - –æ–±—Ä–∞–±–æ—Ç–∫–∞ –ø–æ –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç—É
‚úÖ **Low latency** - –∫—Ä–∏—Ç–∏—á–Ω–∞ –º–∏–Ω–∏–º–∞–ª—å–Ω–∞—è –∑–∞–¥–µ—Ä–∂–∫–∞
‚úÖ **Simple use cases** - CRUD –æ–ø–µ—Ä–∞—Ü–∏–∏, –ø—Ä–æ—Å—Ç—ã–µ –æ—á–µ—Ä–µ–¥–∏
‚úÖ **Message TTL** - —Å–æ–æ–±—â–µ–Ω–∏—è —Å –≤—Ä–µ–º–µ–Ω–µ–º –∂–∏–∑–Ω–∏
‚úÖ **Dead letter queues** - –æ–±—Ä–∞–±–æ—Ç–∫–∞ failed messages

---

## üîß PHP –∏ Kafka

### –ë–∏–±–ª–∏–æ—Ç–µ–∫–∏

**1. php-rdkafka (—Ä–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è)**

```bash
# –£—Å—Ç–∞–Ω–æ–≤–∫–∞ —Ä–∞—Å—à–∏—Ä–µ–Ω–∏—è
pecl install rdkafka

# php.ini
extension=rdkafka.so
```

**2. Composer packages**

```bash
composer require kwn/php-rdkafka
# –∏–ª–∏
composer require enqueue/rdkafka
```

### Producer - –±–∞–∑–æ–≤—ã–π –ø—Ä–∏–º–µ—Ä

```php
<?php

use RdKafka\Producer;
use RdKafka\ProducerTopic;
use RdKafka\Conf;

// –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è
$conf = new Conf();
$conf->set('metadata.broker.list', 'localhost:9092');
$conf->set('client.id', 'php-producer');

// –°–æ–∑–¥–∞—Ç—å producer
$producer = new Producer($conf);

// Topic
$topic = $producer->newTopic('user_events');

// –û—Ç–ø—Ä–∞–≤–∏—Ç—å —Å–æ–æ–±—â–µ–Ω–∏–µ
$message = json_encode([
    'user_id' => 123,
    'event' => 'user_registered',
    'timestamp' => time(),
]);

$topic->produce(
    RD_KAFKA_PARTITION_UA,  // partition: UA = unassigned (auto)
    0,                       // msgflags
    $message,                // payload
    'user:123'               // key (–¥–ª—è –ø–∞—Ä—Ç–∏—Ü–∏–æ–Ω–∏—Ä–æ–≤–∞–Ω–∏—è)
);

// Poll –¥–ª—è callbacks –∏ –¥–æ—Å—Ç–∞–≤–∫–∏
$producer->poll(0);

// Flush - –¥–æ–∂–¥–∞—Ç—å—Å—è –¥–æ—Å—Ç–∞–≤–∫–∏ –≤—Å–µ—Ö —Å–æ–æ–±—â–µ–Ω–∏–π
$producer->flush(10000);  // timeout 10 —Å–µ–∫—É–Ω–¥

echo "Message sent!\n";
```

### Producer —Å partition key

```php
<?php

// –°–æ–æ–±—â–µ–Ω–∏—è —Å –æ–¥–∏–Ω–∞–∫–æ–≤—ã–º –∫–ª—é—á–æ–º –ø–æ–ø–∞–¥—É—Ç –≤ –æ–¥–∏–Ω partition
// ‚Üí –≥–∞—Ä–∞–Ω—Ç–∏—è –ø–æ—Ä—è–¥–∫–∞ –¥–ª—è —Å–æ–±—ã—Ç–∏–π –æ–¥–Ω–æ–≥–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è

$users = [123, 456, 789];

foreach ($users as $userId) {
    $message = json_encode([
        'user_id' => $userId,
        'action' => 'login',
        'timestamp' => time(),
    ]);
    
    // Key = user_id ‚Üí –≤—Å–µ —Å–æ–±—ã—Ç–∏—è —é–∑–µ—Ä–∞ –≤ –æ–¥–Ω–æ–º partition
    $topic->produce(
        RD_KAFKA_PARTITION_UA,
        0,
        $message,
        "user:{$userId}"  // –∫–ª—é—á –ø–∞—Ä—Ç–∏—Ü–∏–æ–Ω–∏—Ä–æ–≤–∞–Ω–∏—è
    );
}

$producer->poll(0);
$producer->flush(10000);
```

### Producer —Å delivery callback

```php
<?php

// Callback –ø—Ä–∏ –¥–æ—Å—Ç–∞–≤–∫–µ/–æ—à–∏–±–∫–µ
$conf->setDrMsgCb(function ($kafka, $message) {
    if ($message->err) {
        echo "Delivery failed: {$message->errstr()}\n";
    } else {
        echo "Message delivered to partition {$message->partition}, offset {$message->offset}\n";
    }
});

$producer = new Producer($conf);
$topic = $producer->newTopic('orders');

$topic->produce(RD_KAFKA_PARTITION_UA, 0, 'Order #123', 'order:123');

// Poll –¥–ª—è –≤—ã–∑–æ–≤–∞ callbacks
for ($i = 0; $i < 10; $i++) {
    $producer->poll(100);
}
```

### Consumer - –±–∞–∑–æ–≤—ã–π –ø—Ä–∏–º–µ—Ä

```php
<?php

use RdKafka\Consumer;
use RdKafka\ConsumerTopic;
use RdKafka\Conf;

// –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è
$conf = new Conf();
$conf->set('metadata.broker.list', 'localhost:9092');
$conf->set('group.id', 'php-consumer-group');
$conf->set('auto.offset.reset', 'earliest');  // earliest | latest

// –°–æ–∑–¥–∞—Ç—å consumer
$consumer = new Consumer($conf);

// Topic
$topic = $consumer->newTopic('user_events');

// –ù–∞—á–∞—Ç—å —á—Ç–µ–Ω–∏–µ —Å partition 0, offset stored
$topic->consumeStart(0, RD_KAFKA_OFFSET_STORED);

echo "Waiting for messages...\n";

while (true) {
    // Poll —Å–æ–æ–±—â–µ–Ω–∏–µ —Å timeout 1 —Å–µ–∫—É–Ω–¥–∞
    $message = $topic->consume(0, 1000);
    
    switch ($message->err) {
        case RD_KAFKA_RESP_ERR_NO_ERROR:
            // –£—Å–ø–µ—à–Ω–æ –ø–æ–ª—É—á–µ–Ω–æ —Å–æ–æ–±—â–µ–Ω–∏–µ
            echo "Received: {$message->payload}\n";
            echo "Partition: {$message->partition}, Offset: {$message->offset}\n";
            
            // –û–±—Ä–∞–±–æ—Ç–∞—Ç—å —Å–æ–æ–±—â–µ–Ω–∏–µ
            processMessage(json_decode($message->payload, true));
            
            break;
            
        case RD_KAFKA_RESP_ERR__PARTITION_EOF:
            // –î–æ—Å—Ç–∏–≥–Ω—É—Ç –∫–æ–Ω–µ—Ü partition (–Ω–µ—Ç –Ω–æ–≤—ã—Ö —Å–æ–æ–±—â–µ–Ω–∏–π)
            echo "End of partition reached\n";
            break;
            
        case RD_KAFKA_RESP_ERR__TIMED_OUT:
            // Timeout - –Ω–µ—Ç —Å–æ–æ–±—â–µ–Ω–∏–π
            echo "Timeout\n";
            break;
            
        default:
            // –û—à–∏–±–∫–∞
            throw new Exception($message->errstr(), $message->err);
    }
}

function processMessage(array $event): void
{
    echo "Processing: {$event['event']} for user {$event['user_id']}\n";
}
```

### High-Level Consumer (—Ä–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è)

```php
<?php

use RdKafka\KafkaConsumer;
use RdKafka\Conf;

// –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è
$conf = new Conf();
$conf->set('metadata.broker.list', 'localhost:9092');
$conf->set('group.id', 'my-consumer-group');
$conf->set('auto.offset.reset', 'earliest');
$conf->set('enable.auto.commit', 'false');  // manual commit

// –°–æ–∑–¥–∞—Ç—å high-level consumer
$consumer = new KafkaConsumer($conf);

// –ü–æ–¥–ø–∏—Å–∞—Ç—å—Å—è –Ω–∞ topics (–º–æ–∂–Ω–æ –Ω–µ—Å–∫–æ–ª—å–∫–æ)
$consumer->subscribe(['user_events', 'order_events']);

echo "Waiting for messages...\n";

while (true) {
    $message = $consumer->consume(1000);  // timeout 1 —Å–µ–∫
    
    switch ($message->err) {
        case RD_KAFKA_RESP_ERR_NO_ERROR:
            // –û–±—Ä–∞–±–æ—Ç–∞—Ç—å —Å–æ–æ–±—â–µ–Ω–∏–µ
            $data = json_decode($message->payload, true);
            processEvent($data);
            
            // Commit offset –ø–æ—Å–ª–µ —É—Å–ø–µ—à–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏
            $consumer->commit($message);
            
            echo "Processed: {$message->topic} [{$message->partition}] offset {$message->offset}\n";
            break;
            
        case RD_KAFKA_RESP_ERR__PARTITION_EOF:
            echo "No more messages\n";
            break;
            
        case RD_KAFKA_RESP_ERR__TIMED_OUT:
            echo "Timed out\n";
            break;
            
        default:
            throw new Exception($message->errstr(), $message->err);
    }
}

function processEvent(array $data): void
{
    // –ë–∏–∑–Ω–µ—Å-–ª–æ–≥–∏–∫–∞
    echo "Event: {$data['event']}\n";
}
```

---

## üé® Laravel –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è

### Laravel Queue Driver

```bash
composer require enqueue/laravel-queue
```

**config/queue.php:**

```php
'connections' => [
    'kafka' => [
        'driver' => 'kafka',
        'queue' => 'default',
        'brokers' => env('KAFKA_BROKERS', 'localhost:9092'),
        'group_id' => env('KAFKA_CONSUMER_GROUP', 'laravel'),
        'consumer' => [
            'enable.auto.commit' => 'false',
            'auto.offset.reset' => 'earliest',
        ],
    ],
],
```

**Job dispatch:**

```php
<?php

namespace App\Jobs;

use Illuminate\Bus\Queueable;
use Illuminate\Contracts\Queue\ShouldQueue;
use Illuminate\Queue\InteractsWithQueue;

class ProcessUserEvent implements ShouldQueue
{
    use InteractsWithQueue, Queueable;
    
    public function __construct(
        public int $userId,
        public string $event,
    ) {}
    
    public function handle(): void
    {
        // –û–±—Ä–∞–±–æ—Ç–∫–∞ —Å–æ–±—ã—Ç–∏—è
        echo "Processing {$this->event} for user {$this->userId}\n";
    }
}

// Dispatch –Ω–∞ Kafka
ProcessUserEvent::dispatch(123, 'user_registered')
    ->onQueue('user_events');
```

**Worker:**

```bash
php artisan queue:work kafka --queue=user_events
```

### Laravel Kafka Package (mateusjunges/laravel-kafka)

```bash
composer require mateusjunges/laravel-kafka
```

**Publish:**

```php
<?php

use Junges\Kafka\Facades\Kafka;
use Junges\Kafka\Message\Message;

// –ü—Ä–æ—Å—Ç–∞—è –ø—É–±–ª–∏–∫–∞—Ü–∏—è
Kafka::publishOn('user_events')
    ->withMessage(new Message(
        body: ['user_id' => 123, 'event' => 'login']
    ))
    ->send();

// –° –∫–ª—é—á–æ–º (–ø–∞—Ä—Ç–∏—Ü–∏–æ–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ)
Kafka::publishOn('orders')
    ->withMessage(
        new Message(
            body: ['order_id' => 456, 'amount' => 100],
            key: 'order:456'
        )
    )
    ->send();

// Batch
$messages = [
    new Message(body: ['user_id' => 1]),
    new Message(body: ['user_id' => 2]),
    new Message(body: ['user_id' => 3]),
];

Kafka::publishOn('user_events')
    ->withMessages($messages)
    ->send();
```

**Consume:**

```php
<?php

use Junges\Kafka\Facades\Kafka;
use Junges\Kafka\Contracts\KafkaConsumerMessage;

$consumer = Kafka::createConsumer(['user_events'])
    ->withConsumerGroupId('my-group')
    ->withHandler(function (KafkaConsumerMessage $message) {
        $data = $message->getBody();
        
        // –û–±—Ä–∞–±–æ—Ç–∞—Ç—å —Å–æ–æ–±—â–µ–Ω–∏–µ
        processEvent($data);
    })
    ->build();

$consumer->consume();
```

**Consumer –≤ –∫–æ–º–∞–Ω–¥–µ:**

```php
<?php

namespace App\Console\Commands;

use Illuminate\Console\Command;
use Junges\Kafka\Facades\Kafka;

class ConsumeUserEvents extends Command
{
    protected $signature = 'kafka:consume-users';
    
    public function handle(): void
    {
        $this->info('Starting Kafka consumer...');
        
        Kafka::createConsumer(['user_events'])
            ->withConsumerGroupId('laravel-consumers')
            ->withAutoCommit()
            ->withHandler(function ($message) {
                $data = $message->getBody();
                $this->info("Event: {$data['event']}");
                
                // Dispatch Laravel job
                ProcessUserEvent::dispatch($data['user_id'], $data['event']);
            })
            ->build()
            ->consume();
    }
}
```

---

## üéØ Use Cases

### 1. Event Sourcing

**–•—Ä–∞–Ω–µ–Ω–∏–µ –≤—Å–µ—Ö –¥–æ–º–µ–Ω–Ω—ã—Ö —Å–æ–±—ã—Ç–∏–π –≤ Kafka.**

```php
<?php

// Domain Events
class UserRegistered
{
    public function __construct(
        public int $userId,
        public string $email,
        public DateTime $occurredAt,
    ) {}
}

class OrderPlaced
{
    public function __construct(
        public int $orderId,
        public int $userId,
        public float $amount,
        public DateTime $occurredAt,
    ) {}
}

// Event Store (Kafka)
class KafkaEventStore
{
    private ProducerTopic $topic;
    
    public function __construct(private Producer $producer)
    {
        $this->topic = $producer->newTopic('domain_events');
    }
    
    public function append(object $event): void
    {
        $message = json_encode([
            'type' => get_class($event),
            'data' => serialize($event),
            'occurred_at' => time(),
        ]);
        
        // –ö–ª—é—á = aggregate ID –¥–ª—è ordering
        $key = $this->extractAggregateId($event);
        
        $this->topic->produce(
            RD_KAFKA_PARTITION_UA,
            0,
            $message,
            $key
        );
        
        $this->producer->flush(5000);
    }
    
    private function extractAggregateId(object $event): string
    {
        if ($event instanceof UserRegistered) {
            return "user:{$event->userId}";
        }
        if ($event instanceof OrderPlaced) {
            return "order:{$event->orderId}";
        }
        return 'unknown';
    }
}

// –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ
$eventStore = new KafkaEventStore($producer);

$event = new UserRegistered(
    userId: 123,
    email: 'user@example.com',
    occurredAt: new DateTime()
);

$eventStore->append($event);  // –í Kafka –Ω–∞–≤—Å–µ–≥–¥–∞
```

**Replay events - –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏–µ —Å–æ—Å—Ç–æ—è–Ω–∏—è:**

```php
<?php

class UserProjection
{
    private array $users = [];
    
    public function rebuild(KafkaConsumer $consumer): void
    {
        // –ß–∏—Ç–∞—Ç—å —Å –Ω–∞—á–∞–ª–∞ topic
        $consumer->subscribe(['domain_events']);
        
        while (true) {
            $message = $consumer->consume(1000);
            
            if ($message->err === RD_KAFKA_RESP_ERR_NO_ERROR) {
                $event = json_decode($message->payload, true);
                $this->apply($event);
            }
        }
    }
    
    private function apply(array $event): void
    {
        switch ($event['type']) {
            case 'UserRegistered':
                $data = unserialize($event['data']);
                $this->users[$data->userId] = [
                    'email' => $data->email,
                    'registered_at' => $data->occurredAt,
                ];
                break;
        }
    }
}
```

### 2. CQRS (Command Query Responsibility Segregation)

**Write model –ø–∏—à–µ—Ç –≤ –ë–î –∏ –ø—É–±–ª–∏–∫—É–µ—Ç —Å–æ–±—ã—Ç–∏—è –≤ Kafka. Query model –ø–æ–¥–ø–∏—Å–∞–Ω –Ω–∞ Kafka –∏ –æ–±–Ω–æ–≤–ª—è–µ—Ç read-–º–æ–¥–µ–ª—å.**

```php
<?php

// Write Side (Command Handler)
class CreateOrderHandler
{
    public function __construct(
        private OrderRepository $repository,
        private Producer $kafka,
    ) {}
    
    public function handle(CreateOrderCommand $command): void
    {
        // 1. –°–æ–∑–¥–∞—Ç—å Order –≤ write DB
        $order = Order::create([
            'user_id' => $command->userId,
            'items' => $command->items,
            'total' => $command->total,
        ]);
        
        $this->repository->save($order);
        
        // 2. –û–ø—É–±–ª–∏–∫–æ–≤–∞—Ç—å —Å–æ–±—ã—Ç–∏–µ –≤ Kafka
        $event = [
            'type' => 'OrderCreated',
            'order_id' => $order->id,
            'user_id' => $order->user_id,
            'total' => $order->total,
            'created_at' => $order->created_at,
        ];
        
        $topic = $this->kafka->newTopic('order_events');
        $topic->produce(
            RD_KAFKA_PARTITION_UA,
            0,
            json_encode($event),
            "order:{$order->id}"
        );
        
        $this->kafka->flush(5000);
    }
}

// Read Side (Consumer)
class OrderQueryModelUpdater
{
    public function consume(KafkaConsumer $consumer): void
    {
        $consumer->subscribe(['order_events']);
        
        while (true) {
            $message = $consumer->consume(1000);
            
            if ($message->err === RD_KAFKA_RESP_ERR_NO_ERROR) {
                $event = json_decode($message->payload, true);
                
                if ($event['type'] === 'OrderCreated') {
                    // –û–±–Ω–æ–≤–∏—Ç—å read model (Redis, Elasticsearch, –¥–µ–Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω–∞—è —Ç–∞–±–ª–∏—Ü–∞)
                    Redis::hset("user:{$event['user_id']}:orders", $event['order_id'], json_encode($event));
                    
                    // –û–±–Ω–æ–≤–∏—Ç—å —Å—á–µ—Ç—á–∏–∫
                    Redis::incr("user:{$event['user_id']}:order_count");
                }
                
                $consumer->commit($message);
            }
        }
    }
}
```

### 3. Log Aggregation

**–¶–µ–Ω—Ç—Ä–∞–ª–∏–∑–æ–≤–∞–Ω–Ω–æ–µ —Ö—Ä–∞–Ω–µ–Ω–∏–µ –ª–æ–≥–æ–≤ —Å –º–Ω–æ–∂–µ—Å—Ç–≤–∞ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–π.**

```php
<?php

// Monolog Handler –¥–ª—è Kafka
use Monolog\Logger;
use Monolog\Handler\AbstractProcessingHandler;

class KafkaHandler extends AbstractProcessingHandler
{
    private ProducerTopic $topic;
    
    public function __construct(
        Producer $producer,
        string $topic = 'application_logs',
        int $level = Logger::DEBUG
    ) {
        parent::__construct($level);
        $this->topic = $producer->newTopic($topic);
    }
    
    protected function write(array $record): void
    {
        $message = json_encode([
            'app' => 'my-app',
            'level' => $record['level_name'],
            'message' => $record['message'],
            'context' => $record['context'],
            'timestamp' => $record['datetime']->format('Y-m-d H:i:s'),
        ]);
        
        $this->topic->produce(
            RD_KAFKA_PARTITION_UA,
            0,
            $message
        );
    }
}

// Laravel config/logging.php
'channels' => [
    'kafka' => [
        'driver' => 'monolog',
        'handler' => KafkaHandler::class,
        'with' => [
            'producer' => app(Producer::class),
            'topic' => 'laravel_logs',
        ],
    ],
],

// –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ
Log::channel('kafka')->info('User registered', ['user_id' => 123]);
```

### 4. Real-time Analytics

**–ü–æ—Ç–æ–∫–æ–≤–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ —Å–æ–±—ã—Ç–∏–π –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π.**

```php
<?php

// Producer: –æ—Ç–ø—Ä–∞–≤–∫–∞ —Å–æ–±—ã—Ç–∏–π –∞–Ω–∞–ª–∏—Ç–∏–∫–∏
class AnalyticsTracker
{
    public function __construct(private Producer $kafka) {}
    
    public function track(string $event, array $properties): void
    {
        $message = json_encode([
            'event' => $event,
            'properties' => $properties,
            'timestamp' => microtime(true),
        ]);
        
        $topic = $this->kafka->newTopic('analytics_events');
        $topic->produce(RD_KAFKA_PARTITION_UA, 0, $message);
        $this->kafka->poll(0);
    }
}

// –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ
$tracker = new AnalyticsTracker($producer);

$tracker->track('page_view', [
    'user_id' => 123,
    'page' => '/products/laptop',
    'referrer' => 'google.com',
]);

$tracker->track('purchase', [
    'user_id' => 123,
    'product_id' => 456,
    'amount' => 999.99,
]);

// Consumer: –∞–≥—Ä–µ–≥–∞—Ü–∏—è –≤ —Ä–µ–∞–ª—å–Ω–æ–º –≤—Ä–µ–º–µ–Ω–∏
class RealTimeStatsAggregator
{
    private array $stats = [];
    
    public function consume(KafkaConsumer $consumer): void
    {
        $consumer->subscribe(['analytics_events']);
        
        while (true) {
            $message = $consumer->consume(100);
            
            if ($message->err === RD_KAFKA_RESP_ERR_NO_ERROR) {
                $event = json_decode($message->payload, true);
                
                // –ê–≥—Ä–µ–≥–∏—Ä–æ–≤–∞—Ç—å –≤ –ø–∞–º—è—Ç–∏ (–∏–ª–∏ Redis)
                $minute = date('Y-m-d H:i', $event['timestamp']);
                $this->stats[$minute][$event['event']] ??= 0;
                $this->stats[$minute][$event['event']]++;
                
                // –ö–∞–∂–¥—ã–µ 60 —Å–µ–∫—É–Ω–¥ - —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å –≤ –ë–î
                $this->flushIfNeeded();
            }
        }
    }
}
```

### 5. CDC (Change Data Capture)

**–û—Ç—Å–ª–µ–∂–∏–≤–∞–Ω–∏–µ –∏–∑–º–µ–Ω–µ–Ω–∏–π –≤ –ë–î —á–µ—Ä–µ–∑ Kafka Connect + Debezium.**

```yaml
# Debezium MySQL Connector
{
  "name": "mysql-connector",
  "config": {
    "connector.class": "io.debezium.connector.mysql.MySqlConnector",
    "database.hostname": "localhost",
    "database.port": "3306",
    "database.user": "debezium",
    "database.password": "secret",
    "database.server.id": "184054",
    "database.server.name": "mydb",
    "table.include.list": "mydb.users,mydb.orders",
    "database.history.kafka.bootstrap.servers": "kafka:9092",
    "database.history.kafka.topic": "schema-changes"
  }
}
```

**Consumer –∏–∑–º–µ–Ω–µ–Ω–∏–π:**

```php
<?php

// Kafka –ø–æ–ª—É—á–∞–µ—Ç CDC —Å–æ–±—ã—Ç–∏—è –æ—Ç Debezium
$consumer = new KafkaConsumer($conf);
$consumer->subscribe(['mydb.users', 'mydb.orders']);

while (true) {
    $message = $consumer->consume(1000);
    
    if ($message->err === RD_KAFKA_RESP_ERR_NO_ERROR) {
        $change = json_decode($message->payload, true);
        
        // Debezium —Ñ–æ—Ä–º–∞—Ç
        $operation = $change['op'];  // c = create, u = update, d = delete
        $before = $change['before'] ?? null;
        $after = $change['after'] ?? null;
        
        match ($operation) {
            'c' => handleInsert($after),
            'u' => handleUpdate($before, $after),
            'd' => handleDelete($before),
        };
        
        $consumer->commit($message);
    }
}

function handleInsert(array $data): void
{
    // –°–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∏—Ä–æ–≤–∞—Ç—å –≤ Elasticsearch
    Elasticsearch::index('users', $data['id'], $data);
}

function handleUpdate(array $before, array $after): void
{
    Elasticsearch::update('users', $after['id'], $after);
}

function handleDelete(array $data): void
{
    Elasticsearch::delete('users', $data['id']);
}
```

### 6. Microservices Communication

**–ê—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–∞—è –∫–æ–º–º—É–Ω–∏–∫–∞—Ü–∏—è –º–µ–∂–¥—É –º–∏–∫—Ä–æ—Å–µ—Ä–≤–∏—Å–∞–º–∏.**

```php
<?php

// Order Service: –ø—É–±–ª–∏–∫—É–µ—Ç —Å–æ–±—ã—Ç–∏–µ
class OrderService
{
    public function placeOrder(PlaceOrderRequest $request): Order
    {
        // 1. –°–æ–∑–¥–∞—Ç—å –∑–∞–∫–∞–∑
        $order = Order::create([
            'user_id' => $request->userId,
            'items' => $request->items,
            'total' => $request->total,
        ]);
        
        // 2. –û–ø—É–±–ª–∏–∫–æ–≤–∞—Ç—å —Å–æ–±—ã—Ç–∏–µ OrderPlaced
        $this->kafka->publish('order_events', [
            'type' => 'OrderPlaced',
            'order_id' => $order->id,
            'user_id' => $order->user_id,
            'total' => $order->total,
        ]);
        
        return $order;
    }
}

// Payment Service: —Å–ª—É—à–∞–µ—Ç OrderPlaced
class PaymentService
{
    public function consumeOrders(): void
    {
        $consumer = Kafka::createConsumer(['order_events'])
            ->withHandler(function ($message) {
                $event = $message->getBody();
                
                if ($event['type'] === 'OrderPlaced') {
                    // –û–±—Ä–∞–±–æ—Ç–∞—Ç—å –ø–ª–∞—Ç–µ–∂
                    $payment = $this->processPayment($event['order_id'], $event['total']);
                    
                    // –û–ø—É–±–ª–∏–∫–æ–≤–∞—Ç—å —Å–æ–±—ã—Ç–∏–µ PaymentProcessed
                    Kafka::publishOn('payment_events')
                        ->withMessage(['type' => 'PaymentProcessed', 'order_id' => $event['order_id']])
                        ->send();
                }
            })
            ->build();
            
        $consumer->consume();
    }
}

// Inventory Service: —Å–ª—É—à–∞–µ—Ç PaymentProcessed
class InventoryService
{
    public function consumePayments(): void
    {
        $consumer = Kafka::createConsumer(['payment_events'])
            ->withHandler(function ($message) {
                $event = $message->getBody();
                
                if ($event['type'] === 'PaymentProcessed') {
                    // –ó–∞—Ä–µ–∑–µ—Ä–≤–∏—Ä–æ–≤–∞—Ç—å —Ç–æ–≤–∞—Ä
                    $this->reserveItems($event['order_id']);
                }
            })
            ->build();
            
        $consumer->consume();
    }
}
```

---

## üìã Topics –∏ Partitions

### –°–æ–∑–¥–∞–Ω–∏–µ Topic

```bash
# CLI
kafka-topics.sh --create \
    --bootstrap-server localhost:9092 \
    --topic user_events \
    --partitions 3 \
    --replication-factor 2

# –ü–∞—Ä–∞–º–µ—Ç—Ä—ã:
# --partitions - –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–∞—Ä—Ç–∏—Ü–∏–π (–ø–∞—Ä–∞–ª–ª–µ–ª–∏–∑–º)
# --replication-factor - –∫–æ–ø–∏–∏ –¥–∞–Ω–Ω—ã—Ö (fault tolerance)
```

**–í—ã–±–æ—Ä –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ partitions:**

```
Partitions = max(throughput, consumers)

# –ü—Ä–∏–º–µ—Ä:
# Throughput: 100 MB/s
# Consumer throughput: 10 MB/s
# Partitions >= 100 / 10 = 10

# –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏:
# - –ù–∞—á–∞—Ç—å —Å 3-5 partitions
# - –ú–æ–∂–Ω–æ —É–≤–µ–ª–∏—á–∏—Ç—å (–Ω–µ–ª—å–∑—è —É–º–µ–Ω—å—à–∏—Ç—å!)
# - –°–ª–∏—à–∫–æ–º –º–Ω–æ–≥–æ partitions ‚Üí overhead
```

### Partition Strategy

**1. Key-based (default):**

```php
// –°–æ–æ–±—â–µ–Ω–∏—è —Å –æ–¥–∏–Ω–∞–∫–æ–≤—ã–º –∫–ª—é—á–æ–º ‚Üí –æ–¥–∏–Ω partition
$topic->produce(RD_KAFKA_PARTITION_UA, 0, $message, "user:123");
$topic->produce(RD_KAFKA_PARTITION_UA, 0, $message, "user:123");  // ‚Üí —Ç–æ—Ç –∂–µ partition

// Hash(key) % partitions_count = partition_number
// "user:123" ‚Üí hash ‚Üí partition 1
```

**2. Round-robin (–±–µ–∑ –∫–ª—é—á–∞):**

```php
// –ù–µ—Ç –∫–ª—é—á–∞ ‚Üí round-robin —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ
$topic->produce(RD_KAFKA_PARTITION_UA, 0, $message1, null);  // ‚Üí partition 0
$topic->produce(RD_KAFKA_PARTITION_UA, 0, $message2, null);  // ‚Üí partition 1
$topic->produce(RD_KAFKA_PARTITION_UA, 0, $message3, null);  // ‚Üí partition 2
```

**3. Custom partitioner:**

```php
// –£–∫–∞–∑–∞—Ç—å –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–π partition
$topic->produce(
    2,  // –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–π partition ID
    0,
    $message
);
```

### Partition Key Best Practices

```php
<?php

// ‚úÖ –•–æ—Ä–æ—à–∏–µ –∫–ª—é—á–∏ –ø–∞—Ä—Ç–∏—Ü–∏–æ–Ω–∏—Ä–æ–≤–∞–Ω–∏—è

// 1. User ID - —Å–æ–±—ã—Ç–∏—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è —É–ø–æ—Ä—è–¥–æ—á–µ–Ω—ã
$key = "user:{$userId}";

// 2. Order ID - —Å–æ–±—ã—Ç–∏—è –∑–∞–∫–∞–∑–∞ —É–ø–æ—Ä—è–¥–æ—á–µ–Ω—ã
$key = "order:{$orderId}";

// 3. Device ID - —Å–æ–±—ã—Ç–∏—è —É—Å—Ç—Ä–æ–π—Å—Ç–≤–∞
$key = "device:{$deviceId}";

// 4. Tenant ID (multi-tenancy)
$key = "tenant:{$tenantId}";

// ‚ùå –ü–ª–æ—Ö–∏–µ –∫–ª—é—á–∏

// 1. Timestamp - –≤—Å–µ —Å–æ–æ–±—â–µ–Ω–∏—è –≤ –æ–¥–∏–Ω partition
$key = time();

// 2. Random - –Ω–µ—Ç ordering
$key = uniqid();

// 3. Constant - –≤—Å–µ –≤ –æ–¥–∏–Ω partition
$key = 'constant';
```

---

## üë• Consumer Groups

### Scaling Consumers

```
Topic: orders (4 partitions)

Scenario 1: 2 consumers in group
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Consumer 1           ‚îÇ
‚îÇ Partition 0, 1       ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Consumer 2           ‚îÇ
‚îÇ Partition 2, 3       ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

Scenario 2: 4 consumers in group (optimal)
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ C1   ‚îÇ ‚îÇ C2   ‚îÇ ‚îÇ C3   ‚îÇ ‚îÇ C4   ‚îÇ
‚îÇ P0   ‚îÇ ‚îÇ P1   ‚îÇ ‚îÇ P2   ‚îÇ ‚îÇ P3   ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

Scenario 3: 6 consumers (2 idle!)
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ C1   ‚îÇ ‚îÇ C2   ‚îÇ ‚îÇ C3   ‚îÇ ‚îÇ C4   ‚îÇ ‚îÇ C5   ‚îÇ ‚îÇ C6   ‚îÇ
‚îÇ P0   ‚îÇ ‚îÇ P1   ‚îÇ ‚îÇ P2   ‚îÇ ‚îÇ P3   ‚îÇ ‚îÇ idle ‚îÇ ‚îÇ idle ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

**–ü—Ä–∞–≤–∏–ª–æ:** consumers <= partitions –¥–ª—è —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏.

### Offset Management

**Auto-commit (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é):**

```php
$conf->set('enable.auto.commit', 'true');
$conf->set('auto.commit.interval.ms', '5000');  // –∫–∞–∂–¥—ã–µ 5 —Å–µ–∫—É–Ω–¥

// –†–∏—Å–∫: —Å–æ–æ–±—â–µ–Ω–∏–µ committed –¥–æ –æ–±—Ä–∞–±–æ—Ç–∫–∏ ‚Üí –ø–æ—Ç–µ—Ä—è –ø—Ä–∏ —Å–±–æ–µ
```

**Manual commit (—Ä–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è):**

```php
$conf->set('enable.auto.commit', 'false');

$consumer = new KafkaConsumer($conf);
$consumer->subscribe(['orders']);

while (true) {
    $message = $consumer->consume(1000);
    
    if ($message->err === RD_KAFKA_RESP_ERR_NO_ERROR) {
        try {
            // –û–±—Ä–∞–±–æ—Ç–∞—Ç—å
            processOrder($message->payload);
            
            // Commit –ü–û–°–õ–ï —É—Å–ø–µ—à–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏
            $consumer->commit($message);
            
        } catch (Exception $e) {
            // –û—à–∏–±–∫–∞ - –ù–ï commit, –ø–µ—Ä–µ–æ–±—Ä–∞–±–æ—Ç–∞–µ–º
            Log::error("Failed to process: {$e->getMessage()}");
        }
    }
}
```

**Commit strategies:**

```php
// 1. Commit –∫–∞–∂–¥–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ (–º–µ–¥–ª–µ–Ω–Ω–æ, –Ω–æ –±–µ–∑–æ–ø–∞—Å–Ω–æ)
$consumer->commit($message);

// 2. Commit batch (–±—ã—Å—Ç—Ä–µ–µ, —Ä–∏—Å–∫ –ø–æ—Ç–µ—Ä–∏ batch)
$processed = 0;
while (true) {
    $message = $consumer->consume(1000);
    process($message);
    $processed++;
    
    if ($processed >= 100) {
        $consumer->commit($message);  // commit –∫–∞–∂–¥—ã–µ 100 —Å–æ–æ–±—â–µ–Ω–∏–π
        $processed = 0;
    }
}

// 3. Commit —Å async (–Ω–µ –∂–¥–∞—Ç—å –ø–æ–¥—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏—è)
$consumer->commitAsync($message);
```

### Offset Reset

```php
// auto.offset.reset - —á—Ç–æ –¥–µ–ª–∞—Ç—å –µ—Å–ª–∏ –Ω–µ—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω–Ω–æ–≥–æ offset

// earliest - —á–∏—Ç–∞—Ç—å —Å –Ω–∞—á–∞–ª–∞ topic
$conf->set('auto.offset.reset', 'earliest');

// latest - —á–∏—Ç–∞—Ç—å —Ç–æ–ª—å–∫–æ –Ω–æ–≤—ã–µ —Å–æ–æ–±—â–µ–Ω–∏—è (default)
$conf->set('auto.offset.reset', 'latest');

// none - –æ—à–∏–±–∫–∞ –µ—Å–ª–∏ –Ω–µ—Ç offset
$conf->set('auto.offset.reset', 'none');
```

### Rebalancing

**–ü—Ä–æ–∏—Å—Ö–æ–¥–∏—Ç –∫–æ–≥–¥–∞:**
- Consumer –ø—Ä–∏—Å–æ–µ–¥–∏–Ω—è–µ—Ç—Å—è –∫ –≥—Ä—É–ø–ø–µ
- Consumer –ø–æ–∫–∏–¥–∞–µ—Ç –≥—Ä—É–ø–ø—É (graceful –∏–ª–∏ crash)
- Partitions –¥–æ–±–∞–≤–ª–µ–Ω—ã –≤ topic

```
Before rebalance:
C1 ‚Üí P0, P1
C2 ‚Üí P2, P3

[C3 joins group]
‚Üí Rebalancing...

After rebalance:
C1 ‚Üí P0
C2 ‚Üí P1, P2
C3 ‚Üí P3
```

**Graceful shutdown:**

```php
$running = true;

pcntl_signal(SIGTERM, function () use (&$running) {
    $running = false;
});

while ($running) {
    $message = $consumer->consume(1000);
    // process...
}

// Graceful shutdown
$consumer->close();  // triggers rebalance
```

---

## ‚öôÔ∏è –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è

### Producer Configuration

```php
$conf = new Conf();

// Brokers
$conf->set('metadata.broker.list', 'localhost:9092');

// Acknowledgments (–≤–∞–∂–Ω–æ!)
$conf->set('acks', 'all');  // all | 1 | 0
// all - wait for all ISR (—Å–∞–º–æ–µ –Ω–∞–¥–µ–∂–Ω–æ–µ, –º–µ–¥–ª–µ–Ω–Ω–µ–µ)
// 1 - wait for leader (default)
// 0 - fire and forget (–±—ã—Å—Ç—Ä–æ, –Ω–µ–Ω–∞–¥–µ–∂–Ω–æ)

// Retries
$conf->set('retries', '3');
$conf->set('retry.backoff.ms', '100');

// Compression (—ç–∫–æ–Ω–æ–º–∏—è bandwidth)
$conf->set('compression.type', 'snappy');  // none | gzip | snappy | lz4 | zstd

// Batching (–ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å)
$conf->set('batch.size', '16384');  // bytes
$conf->set('linger.ms', '10');  // wait 10ms for batching

// Idempotence (exactly-once semantics)
$conf->set('enable.idempotence', 'true');
```

### Consumer Configuration

```php
$conf = new Conf();

// Brokers
$conf->set('metadata.broker.list', 'localhost:9092');

// Consumer group
$conf->set('group.id', 'my-consumer-group');

// Offset management
$conf->set('enable.auto.commit', 'false');  // manual commit
$conf->set('auto.offset.reset', 'earliest');

// Session timeout (broker —Å—á–∏—Ç–∞–µ—Ç consumer –º–µ—Ä—Ç–≤—ã–º)
$conf->set('session.timeout.ms', '30000');  // 30 sec

// Heartbeat
$conf->set('heartbeat.interval.ms', '3000');  // 3 sec

// Max poll interval (–≤—Ä–µ–º—è –º–µ–∂–¥—É poll)
$conf->set('max.poll.interval.ms', '300000');  // 5 min

// Fetch size
$conf->set('fetch.min.bytes', '1');
$conf->set('fetch.max.wait.ms', '500');
```

### Broker Configuration

**server.properties:**

```properties
# Cluster
broker.id=0
listeners=PLAINTEXT://localhost:9092
zookeeper.connect=localhost:2181

# Partitions
num.partitions=3
default.replication.factor=2

# Logs
log.dirs=/var/kafka-logs
log.retention.hours=168  # 7 days
log.retention.bytes=-1  # unlimited
log.segment.bytes=1073741824  # 1GB

# Compression
compression.type=producer  # inherit from producer

# ISR
min.insync.replicas=1
```

---

## üé¨ Kafka Streams

**Lightweight –±–∏–±–ª–∏–æ—Ç–µ–∫–∞ –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ –ø–æ—Ç–æ–∫–æ–≤ (Java/Scala, –Ω–µ—Ç –¥–ª—è PHP).**

–ê–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤—ã –¥–ª—è PHP:
1. –°–æ–±—Å—Ç–≤–µ–Ω–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ —Å Consumer
2. Apache Flink (PHP –∫–ª–∏–µ–Ω—Ç —á–µ—Ä–µ–∑ REST API)
3. ksqlDB (SQL over Kafka streams)

**–ü—Ä–∏–º–µ—Ä –æ–±—Ä–∞–±–æ—Ç–∫–∏ –≤ PHP:**

```php
<?php

// Stateful stream processing –≤ PHP
class WordCountProcessor
{
    private array $counts = [];
    
    public function process(KafkaConsumer $consumer): void
    {
        $consumer->subscribe(['text_stream']);
        
        while (true) {
            $message = $consumer->consume(1000);
            
            if ($message->err === RD_KAFKA_RESP_ERR_NO_ERROR) {
                $text = $message->payload;
                $words = explode(' ', strtolower($text));
                
                foreach ($words as $word) {
                    $this->counts[$word] = ($this->counts[$word] ?? 0) + 1;
                }
                
                // Publish results
                $this->publishResults();
                $consumer->commit($message);
            }
        }
    }
    
    private function publishResults(): void
    {
        // Publish top 10 words to output topic
        arsort($this->counts);
        $top10 = array_slice($this->counts, 0, 10, true);
        
        // ... publish to output_topic
    }
}
```

---

## üîå Kafka Connect

**Framework –¥–ª—è –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–∏ Kafka —Å –≤–Ω–µ—à–Ω–∏–º–∏ —Å–∏—Å—Ç–µ–º–∞–º–∏.**

### Source Connectors (–ë–î ‚Üí Kafka)

- **Debezium** (MySQL, PostgreSQL, MongoDB CDC)
- **JDBC Source** (–ª—é–±–∞—è SQL –ë–î)
- **File Source** (—á—Ç–µ–Ω–∏–µ —Ñ–∞–π–ª–æ–≤)

### Sink Connectors (Kafka ‚Üí –ë–î/—Ö—Ä–∞–Ω–∏–ª–∏—â–µ)

- **JDBC Sink** (–ª—é–±–∞—è SQL –ë–î)
- **Elasticsearch Sink**
- **S3 Sink** (AWS S3)
- **Redis Sink**

**–ü—Ä–∏–º–µ—Ä: MySQL ‚Üí Kafka ‚Üí Elasticsearch**

```json
{
  "name": "mysql-source",
  "config": {
    "connector.class": "io.debezium.connector.mysql.MySqlConnector",
    "database.hostname": "mysql",
    "database.port": "3306",
    "database.user": "debezium",
    "database.password": "secret",
    "database.server.name": "mydb",
    "table.include.list": "mydb.products",
    "transforms": "route",
    "transforms.route.type": "org.apache.kafka.connect.transforms.RegexRouter",
    "transforms.route.regex": "([^.]+)\\.([^.]+)\\.([^.]+)",
    "transforms.route.replacement": "$3"
  }
}

{
  "name": "elasticsearch-sink",
  "config": {
    "connector.class": "io.confluent.connect.elasticsearch.ElasticsearchSinkConnector",
    "connection.url": "http://elasticsearch:9200",
    "topics": "products",
    "type.name": "_doc",
    "key.ignore": "false"
  }
}
```

---

## üìä –ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥

### –ú–µ—Ç—Ä–∏–∫–∏ Producer

```php
// Kafka metrics —á–µ—Ä–µ–∑ JMX –∏–ª–∏ rdkafka metadata
$metadata = $producer->getMetadata(true, null, 5000);

foreach ($metadata->getBrokers() as $broker) {
    echo "Broker {$broker->getId()}: {$broker->getHost()}:{$broker->getPort()}\n";
}

foreach ($metadata->getTopics() as $topic) {
    echo "Topic {$topic->getTopic()}: {$topic->getPartitions()->count()} partitions\n";
}
```

### –ö–ª—é—á–µ–≤—ã–µ –º–µ—Ç—Ä–∏–∫–∏

**Broker:**
- `UnderReplicatedPartitions` - –ø–∞—Ä—Ç–∏—Ü–∏–∏ –±–µ–∑ –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ–≥–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ —Ä–µ–ø–ª–∏–∫
- `OfflinePartitionsCount` - –Ω–µ–¥–æ—Å—Ç—É–ø–Ω—ã–µ –ø–∞—Ä—Ç–∏—Ü–∏–∏
- `ActiveControllerCount` - –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å 1
- `RequestHandlerAvgIdlePercent` - –Ω–∞–≥—Ä—É–∑–∫–∞ –Ω–∞ broker

**Producer:**
- `record-send-rate` - —Å–æ–æ–±—â–µ–Ω–∏–π –≤ —Å–µ–∫—É–Ω–¥—É
- `record-error-rate` - –æ—à–∏–±–∫–∏ –æ—Ç–ø—Ä–∞–≤–∫–∏
- `request-latency-avg` - —Å—Ä–µ–¥–Ω—è—è –∑–∞–¥–µ—Ä–∂–∫–∞

**Consumer:**
- `records-lag` - –æ—Ç—Å—Ç–∞–≤–∞–Ω–∏–µ consumer –æ—Ç –∫–æ–Ω—Ü–∞ partition
- `records-consumed-rate` - —Å–æ–æ–±—â–µ–Ω–∏–π –≤ —Å–µ–∫—É–Ω–¥—É
- `commit-latency-avg` - –∑–∞–¥–µ—Ä–∂–∫–∞ commit

### Kafka Manager / CMAK

```bash
# UI –¥–ª—è —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è Kafka
docker run -d \
  -p 9000:9000 \
  -e ZK_HOSTS="zookeeper:2181" \
  hlebalbau/kafka-manager:stable
```

### Prometheus + Grafana

**JMX Exporter –¥–ª—è Kafka:**

```yaml
# kafka-jmx-exporter.yml
lowercaseOutputName: true
rules:
  - pattern: kafka.server<type=(.+), name=(.+)><>Value
    name: kafka_server_$1_$2
```

**Grafana dashboard:** ID 721 (Kafka Overview)

---

## üéì Best Practices

### 1. Partition Keys

```php
// ‚úÖ DO: –ò—Å–ø–æ–ª—å–∑—É–π –∫–ª—é—á–∏ –¥–ª—è ordering
$topic->produce(RD_KAFKA_PARTITION_UA, 0, $message, "user:{$userId}");

// ‚ùå DON'T: –°–ª—É—á–∞–π–Ω—ã–µ –∫–ª—é—á–∏
$topic->produce(RD_KAFKA_PARTITION_UA, 0, $message, uniqid());
```

### 2. Idempotent Consumers

```php
// –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–π —Å–æ–æ–±—â–µ–Ω–∏—è –∏–¥–µ–º–ø–æ—Ç–µ–Ω—Ç–Ω–æ (–ø–æ–≤—Ç–æ—Ä–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ = —Ç–æ—Ç –∂–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç)

// ‚úÖ DO: Upsert —Å —É–Ω–∏–∫–∞–ª—å–Ω—ã–º –∫–ª—é—á–æ–º
DB::table('events')->updateOrInsert(
    ['event_id' => $message->key],  // unique constraint
    ['data' => $message->payload]
);

// ‚ùå DON'T: Increment –±–µ–∑ –ø—Ä–æ–≤–µ—Ä–∫–∏
DB::table('counters')->increment('count');  // –¥—É–±–ª–∏—Ä–æ–≤–∞–Ω–∏–µ –ø—Ä–∏ retry!
```

### 3. Error Handling

```php
// ‚úÖ DO: Retry —Å exponential backoff
$retries = 0;
$maxRetries = 3;

while ($retries < $maxRetries) {
    try {
        processMessage($message);
        $consumer->commit($message);
        break;
    } catch (Exception $e) {
        $retries++;
        $delay = pow(2, $retries) * 100;  // 200ms, 400ms, 800ms
        usleep($delay * 1000);
        
        if ($retries >= $maxRetries) {
            // Dead Letter Queue
            $this->sendToDLQ($message, $e);
        }
    }
}
```

### 4. Schema Evolution

```php
// –ò—Å–ø–æ–ª—å–∑—É–π schema registry (Confluent Schema Registry)

// v1
$schema = [
    'user_id' => 'int',
    'name' => 'string',
];

// v2 - –¥–æ–±–∞–≤–∏–ª–∏ –ø–æ–ª–µ (backward compatible)
$schema = [
    'user_id' => 'int',
    'name' => 'string',
    'email' => 'string',  // –Ω–æ–≤–æ–µ –ø–æ–ª–µ —Å default
];

// Consumer v1 –∏–≥–Ω–æ—Ä–∏—Ä—É–µ—Ç email
// Consumer v2 —á–∏—Ç–∞–µ—Ç email
```

### 5. Monitoring –∏ Alerting

```php
// –¢—Ä–µ–∫–∞–π consumer lag
$lag = $this->getConsumerLag($topic, $partition);

if ($lag > 10000) {
    Alert::send("High lag: {$lag} messages behind");
}

// –ú–æ–Ω–∏—Ç–æ—Ä—å failed messages
if ($failedCount > 100) {
    Alert::send("Too many failed messages");
}
```

### 6. Graceful Shutdown

```php
declare(ticks = 1);

$running = true;

pcntl_signal(SIGTERM, function () use (&$running) {
    echo "Shutting down gracefully...\n";
    $running = false;
});

while ($running) {
    $message = $consumer->consume(1000);
    // process...
}

$consumer->close();  // commit offsets, leave group
echo "Shutdown complete\n";
```

---

## üéì –î–ª—è —Å–æ–±–µ—Å–µ–¥–æ–≤–∞–Ω–∏—è: –∫–ª—é—á–µ–≤—ã–µ —Ç–æ—á–∫–∏

1. **Kafka = distributed streaming platform** —Å –≤—ã—Å–æ–∫–æ–π –ø—Ä–æ–ø—É—Å–∫–Ω–æ–π —Å–ø–æ—Å–æ–±–Ω–æ—Å—Ç—å—é
2. **Topics –∏ Partitions** - –ø–∞—Ä–∞–ª–ª–µ–ª–∏–∑–º –∏ ordering
3. **Consumer Groups** - –º–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏–µ consumers, load balancing
4. **Offsets** - –ø–æ–∑–∏—Ü–∏—è –≤ partition, commit strategies
5. **Replication** - fault tolerance —á–µ—Ä–µ–∑ leader/follower
6. **Kafka vs RabbitMQ** - streaming vs messaging, retention, throughput
7. **Use cases** - event sourcing, CQRS, log aggregation, CDC, real-time analytics
8. **PHP integration** - rdkafka extension, Laravel packages
9. **Idempotency** - –æ–±—Ä–∞–±–æ—Ç–∫–∞ —Å–æ–æ–±—â–µ–Ω–∏–π –¥–æ–ª–∂–Ω–∞ –±—ã—Ç—å –∏–¥–µ–º–ø–æ—Ç–µ–Ω—Ç–Ω–æ–π
10. **At-least-once delivery** - —Å–æ–æ–±—â–µ–Ω–∏—è –º–æ–≥—É—Ç –¥—É–±–ª–∏—Ä–æ–≤–∞—Ç—å—Å—è (commit –ø–æ—Å–ª–µ –æ–±—Ä–∞–±–æ—Ç–∫–∏)

**–ì–ª–∞–≤–Ω–æ–µ:** –ü–æ–Ω–∏–º–∞–π partition key –¥–ª—è ordering, consumer groups –¥–ª—è scaling, manual commit –¥–ª—è –Ω–∞–¥–µ–∂–Ω–æ—Å—Ç–∏.
